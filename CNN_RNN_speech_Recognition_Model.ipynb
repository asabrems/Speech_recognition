{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNN_RNN_speech Recognition_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2mLliHSSAsn"
      },
      "source": [
        "# **Author**: Adwoa Asantewaa Bremang \n",
        "# **Project**: Speech recognition model training\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "**Description:**\n",
        "\n",
        "The speech were converted to frames of utterances, these utterances had unaligned phonemes as labels. Therefore, the project focused on predicting phonomes mapped to utterance of test data using CNN-LSTM RNN model and CTCLOSS to aid in mapping utterance to phonomes.\n",
        "The model was evaluated using the levenshtein distance. The model trained with approximately 22000 train dataset was able to predict labels for train datasets with an average levenshtein distance of approximately 8."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrmcbrUZygB7"
      },
      "source": [
        "from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24PaQf2FD06q"
      },
      "source": [
        "## Libraries installations "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KDIXQz2jRfy"
      },
      "source": [
        "!pip install python-Levenshtein\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGiGZPx5_GFB"
      },
      "source": [
        "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
        "!pip install wget\n",
        "%cd ctcdecode\n",
        "!pip install .\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jg6yFtSvJMKT"
      },
      "source": [
        "!git clone https://github.com/1ytic/pytorch-edit-distance\n",
        "%cd pytorch-edit-distance\n",
        "!python setup.py install\n",
        "%cd .."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvpo0wA216xR"
      },
      "source": [
        "## Imported classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK4N8Y99zbM4"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import Levenshtein\n",
        "import torchvision   \n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from skimage import io\n",
        "from torchvision import transforms\n",
        "import pandas as pd\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from ctcdecode import CTCBeamDecoder\n",
        "#from torch_edit_distance import *\n",
        "#from pytorch-edit-distance import torch_edit_distance\n",
        "cuda = torch.cuda.is_available()\n",
        "cuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Dk3jnYd2FGa"
      },
      "source": [
        "## loading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxykI439z6Jk"
      },
      "source": [
        "dev = np.load('dev.npy',allow_pickle=True)\n",
        "dev_labels = np.load('dev_labels.npy', allow_pickle=True)\n",
        "test = np.load('test.npy', allow_pickle=True)\n",
        "train = np.load('train.npy', allow_pickle=True)\n",
        "train_labels = np.load('train_labels.npy',allow_pickle=True)\n",
        "print(\"dev.shape\", dev.shape)\n",
        "print(\"dev_label.shape\", dev_labels[0].shape)\n",
        "print(\"test.shape\", test.shape)\n",
        "print(\"train.shape\", train.shape)\n",
        "print(\"train_labels.shape\", train_labels.shape)\n",
        "from phoneme_list import *\n",
        "\n",
        "label_map = PHONEME_MAP"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnuzTNlU3FEf"
      },
      "source": [
        "## dataset loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyzaML7f2MFw"
      },
      "source": [
        "class LibriDataset(Dataset):\n",
        "  def __init__(self,X,y):    \n",
        "    self.X = X\n",
        "    if y is None:\n",
        "      self.y = None\n",
        "    else: \n",
        "      self.y = y\n",
        "\n",
        "  def __len__(self):\n",
        "    length = len(self.X)\n",
        "    return length\n",
        "  \n",
        "  def __getitem__(self,idx):\n",
        "    features = self.X[idx]\n",
        "\n",
        "    labels = None\n",
        "    if self.y is not None: \n",
        "      labels = self.y[idx]+1\n",
        "      return torch.Tensor(features), torch.Tensor(labels)\n",
        "    else:\n",
        "      return torch.Tensor(features)\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRzZQ6kJD9X2"
      },
      "source": [
        "## collate function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwUs1MeomtVt"
      },
      "source": [
        "def collate(batch):\n",
        "    y = []\n",
        "    x = []\n",
        "    x_length = []\n",
        "    y_length =[]\n",
        "    for X,Y in batch:\n",
        "       x.append(X)\n",
        "       y.append(Y)\n",
        "       x_length.append(X.shape[0])\n",
        "       y_length.append(len(Y))\n",
        "    x_out =pad_sequence(x,batch_first=False)\n",
        "    y_out =pad_sequence(y,batch_first=True)\n",
        "\n",
        "    return (x_out, x_length),(y_out,  y_length)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egpXU80S3mIj"
      },
      "source": [
        "def collate_test(batch):\n",
        "    y = []\n",
        "    x = []\n",
        "    x_length = []\n",
        "    y_length =[]\n",
        "    for X in batch:\n",
        "       x.append(X)\n",
        "       x_length.append(X.shape[0])\n",
        "    x_out =pad_sequence(x,batch_first=False)\n",
        "\n",
        "    return (x_out, x_length)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8G6YIZE3fub"
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "train_dataset = LibriDataset(train, train_labels)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size= batch_size  , shuffle=True,num_workers=3, pin_memory=True,collate_fn =lambda b: collate(b))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5roe9PC3jKW"
      },
      "source": [
        "dev_dataset = LibriDataset(dev, dev_labels) \n",
        "dev_loader = DataLoader(dev_dataset, batch_size= batch_size  , shuffle=False,num_workers=3, pin_memory=True,collate_fn =lambda b: collate(b))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0j45kZjA5lx"
      },
      "source": [
        "test_dataset = LibriDataset(test,None)\n",
        "test_loader = DataLoader(test_dataset, batch_size= batch_size  , shuffle=False,num_workers=3, pin_memory=True,collate_fn =lambda b: collate_test(b))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9utag1r3_P5"
      },
      "source": [
        "## Model\n",
        "\n",
        "---\n",
        "\n",
        "  The model is a CNN_LSTM RNN Model. The input data is passed through an 1d CNN model which is average pooled. The output is passed to a bidirectional LSTM model. The output is passed to a linear layer of logSoftmax.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E9MIZ4TDDPG"
      },
      "source": [
        "class model(nn.Module):\n",
        "  def __init__(self, input,hidden_sizes,output, no_layers):   \n",
        "    super(model, self).__init__() \n",
        "    #.......................................................\n",
        "    in_channels = input\n",
        "    out_channels = 128\n",
        "    self.cnn = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "    self.bn = nn.BatchNorm1d(out_channels)\n",
        "    self.avg_pool = nn.AvgPool1d(3, stride=2)\n",
        "        \n",
        "    self.linear = nn.Linear(out_channels , input)\n",
        "\n",
        "    #..........................................................\n",
        "    self.lstm = nn.LSTM(input,hidden_sizes,num_layers = no_layers, bidirectional=True, batch_first=True, dropout = 0.5)\n",
        "    #self.dropout = nn.Dropout(0.4)\n",
        "    #self.linear = nn.Linear(hidden_sizes*2, hidden_sizes*2)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.output = nn.Linear(hidden_sizes * 2, output)\n",
        "\n",
        "  def forward(self,x,lengths):\n",
        "    #print(x.shape)\n",
        "    x = self.cnn(x.permute(0,2,1))\n",
        "    #print(x.shape)\n",
        "    x = self.avg_pool(x)\n",
        "    #print(x.shape)\n",
        "    \n",
        "    x  =torch.nn.utils.rnn.pack_padded_sequence(x, lengths, batch_first=False, enforce_sorted=False)\n",
        "    x = self.lstm(x)[0]\n",
        "    \n",
        "    x, out_lens = torch.nn.utils.rnn.pad_packed_sequence(x, batch_first=False)\n",
        "    x = self.dropout(x)\n",
        "    x = self.output(x).log_softmax(dim = 2)\n",
        "\n",
        "    return x, out_lens\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwMbP8Vi7dUc"
      },
      "source": [
        "## training function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F793pLQH7cbW"
      },
      "source": [
        "\n",
        "def training(model,optimizer,criterion, data_loader,scheduler):\n",
        "  model.train()\n",
        "  loss = 0.0\n",
        "  for i,(train_data,train_label) in enumerate(data_loader):\n",
        "    optimizer.zero_grad()\n",
        "    train_d_ = train_data[0].to(device)\n",
        "    train_d_lens = torch.Tensor(train_data[1]).to(torch.int)\n",
        "    train_l_ = train_label[0].to(device)\n",
        "    train_l_lens = torch.Tensor(train_label[1]).to(torch.int)\n",
        "    print(train_d_.shape,train_d_lens.shape,train_l_.shape,train_l_lens.shape)\n",
        "    m\n",
        "    train_output, out_lens = model(train_d_,train_d_lens)\n",
        "    train_loss = criterion(train_output,train_l_, out_lens,train_l_lens)\n",
        "    loss += train_loss.item()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "    #scheduler.step()\n",
        "    '''if(i == 20):\n",
        "      torch.save(model.state_dict(), 'checkpoint2.pth')'''\n",
        "  loss /= len(data_loader)\n",
        "  print(\"Training loss\", loss)\n",
        "  return loss"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Trhtb-TzEGyR"
      },
      "source": [
        "## Decoder function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7-gFSnu_OoK"
      },
      "source": [
        "decoder = CTCBeamDecoder(\n",
        "    PHONEME_LIST,\n",
        "    model_path=None,\n",
        "    alpha=0,\n",
        "    beta=0,\n",
        "    cutoff_top_n=40,\n",
        "    cutoff_prob=1.0,\n",
        "    beam_width=50,\n",
        "    num_processes=4,\n",
        "    #blank_id=0,\n",
        "    log_probs_input=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RRRvvt0PpEY"
      },
      "source": [
        "def label_string(i):\n",
        "  return label_map[i.numpy().astype(int)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiNB0XRzKuOi"
      },
      "source": [
        "def edit_distance_cal(pred,target):\n",
        "  for i, p in enumerate(pred):\n",
        "    if(i< len(target)):\n",
        "      dis = Levenshtein.distance(p,target[i])\n",
        "  return dis"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H0UrFwu4HqF"
      },
      "source": [
        "def decode_seq(pred):\n",
        "  string_out = []\n",
        "  lens = []\n",
        "  for i, p in enumerate(pred):\n",
        "    string = list(map(label_string, list(p)))\n",
        "\n",
        "    string_out.append((''.join(string)))\n",
        "  return string_out\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTg4Bi8-TnbW"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlBJT-UT7s32"
      },
      "source": [
        "def validation_model(model,criterion,test_loader):\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    dev_loss  =0.0\n",
        "    total_predictions =0.0\n",
        "    correct_predictions =0\n",
        "    predict = 0.0\n",
        "    predict_store = []\n",
        "    target =[]\n",
        "    count = 0\n",
        "    new = []\n",
        "    dis=0\n",
        "    accuracy = 0\n",
        "    for i,(dev_data,dev_label) in enumerate(dev_loader):\n",
        "      \n",
        "      dev_d_ = dev_data[0].to(device)\n",
        "      dev_d_lens = torch.Tensor(dev_data[1]).to(torch.int)\n",
        "      dev_l_ = dev_l[0].to(device)\n",
        "      dev_l_lens = torch.Tensor(dev_label[1]).to(torch.int)\n",
        "      dev_output, out_lens= model(dev_d_,dev_d_lens)\n",
        "   \n",
        "      total_predictions += dev_l_lens.size(0)\n",
        "\n",
        "      dev_loss = criterion(dev_output,dev_l_, out_lens,dev_l_lens)\n",
        "  \n",
        "      dev_loss += dev_loss.item()\n",
        "      predicted = torch.transpose(dev_output, 0,1)\n",
        "      align = []\n",
        "      predict_beam_results, _, _, predict_out_lens = decoder.decode(predicted.data.cpu(),torch.IntTensor(out_lens.to((torch.int))))\n",
        "      for i, out_len in enumerate(predict_out_lens):\n",
        "          align.append(predict_beam_results[i, 0, :predict_out_lens[i, 0]])\n",
        "\n",
        "      pred_seq = decode_seq(align)\n",
        "      target_seq = decode_seq(dev_l_.data.cpu())\n",
        "    \n",
        "      dis = edit_distance_cal(pred_seq,target_seq)\n",
        "      \n",
        "      \n",
        "      predict_store.append(dis)\n",
        "    dis_loss = np.sum(np.array(predict_store))/len(predict_store)\n",
        "    dev_loss /= len(dev_loader) \n",
        "\n",
        "    print(\"edit_distance\",dis_loss)\n",
        "    print(\"Validation loss :\",dev_loss)\n",
        "    \n",
        "    return dev_loss, dis_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KJfiiFYuRyD"
      },
      "source": [
        "def init_weights(layer):\n",
        "        if type(layer) == nn.Linear:\n",
        "           torch.nn.init.kaiming_normal_(layer.weight.data)\n",
        "           #torch.nn.init.xavier_uniform_(layer.weight.data, gain=1.0)\n",
        "        if type(layer) == nn.LSTM:\n",
        "           torch.nn.init.uniform_(layer.weight_hh_l0.data, a=-0.1, b=0.1)\n",
        "           torch.nn.init.uniform_(layer.weight_ih_l0.data, a=-0.1, b=0.1)\n",
        "           torch.nn.init.uniform_(layer.bias_hh_l0.data, a=-0.1, b=0.1)\n",
        "           torch.nn.init.uniform_(layer.bias_ih_l0.data, a=-0.1, b=0.1)\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yv48ci_1nkbz"
      },
      "source": [
        "n_epochs = 30\n",
        "Train_loss = []\n",
        "Test_loss = []\n",
        "Test_acc = []\n",
        "predict =[]\n",
        "input = 13\n",
        "len_phonemes = 42\n",
        "no_layers = 3\n",
        "hidden_sizes = 256\n",
        "model = model(input,hidden_sizes,len_phonemes, no_layers)\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "model.apply(init_weights)\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BI0tUczX-0K8"
      },
      "source": [
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nij_ced3Vay-"
      },
      "source": [
        "\n",
        "\n",
        "criterion = nn.CTCLoss()\n",
        "count = 0\n",
        "weightDecay= 5e-6\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001,weight_decay=weightDecay)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 3, gamma =0.1)\n",
        "for i in range(n_epochs):\n",
        "    train_loss = training(model,optimizer,criterion, train_loader,scheduler)\n",
        "    test_loss, test_dis = validation_model(model,criterion,dev_loader)\n",
        "    \n",
        "    Train_loss.append(train_loss)\n",
        "    Test_loss.append(test_loss)\n",
        "    Test_acc.append(test_dis)\n",
        "    torch.save(model.state_dict(), './gdrive/MyDrive/abremang_hw3p2/checkpoint'+str(i+1)+'.pth')\n",
        "    torch.save(model.state_dict(), 'checkpoint'+str(i+1)+'.pth')\n",
        "    count = count +1\n",
        "    print(\"epoch\",count)\n",
        "    print('='*20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LBiCCv-OUZl"
      },
      "source": [
        "state_dict = torch.load('checkpoint14.pth')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf7mtO0inbst"
      },
      "source": [
        "model.load_state_dict(state_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHLB5c3mT9rd"
      },
      "source": [
        "## Testing "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahot60_QeUur"
      },
      "source": [
        "def test_model(model,test_loader):\n",
        "\n",
        "  dev_loss  =0.0\n",
        "  total_predictions =0.0\n",
        "  correct_predictions =0\n",
        "  output = 0.0\n",
        "  counter =0\n",
        "  store_c = []\n",
        "  predict = []\n",
        "  pred_seq = []\n",
        "  for test_values in test_loader:\n",
        "      test_values_ = test_values[0].to(device)\n",
        "      test_values_lens = torch.Tensor(test_values[1]).to(torch.int)\n",
        "      dev_output, out_len = model(test_values_,test_values_lens)\n",
        "      predicted = torch.transpose(dev_output, 0,1)\n",
        "      align =[]\n",
        "      test_beam_results, _, _, test_out_lens = decoder.decode((predicted.data.cpu()),torch.IntTensor(out_len.to(torch.int)))\n",
        "      for i, out_len in enumerate(test_out_lens):\n",
        "          align.append(test_beam_results[i, 0, :test_out_lens[i, 0]])\n",
        "      deco = decode_seq(align)\n",
        "      predict.append(deco)\n",
        "    \n",
        "\n",
        "  predict = np.concatenate(predict)\n",
        "  return predict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CwrxPvpGZmsK"
      },
      "source": [
        "predict = test_model(model,test_loader)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIH4_lC_d9hW"
      },
      "source": [
        "store_c = np.arange(len(predict))\n",
        "data = {\"id\":store_c,\"label\":predict}\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv(\"data1_epoch14.csv\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}